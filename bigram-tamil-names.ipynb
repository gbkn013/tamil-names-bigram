{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13264607,"sourceType":"datasetVersion","datasetId":8405762}],"dockerImageVersionId":30154,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport random\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2025-10-06T00:58:37.053566Z","iopub.execute_input":"2025-10-06T00:58:37.053939Z","iopub.status.idle":"2025-10-06T00:58:38.379932Z","shell.execute_reply.started":"2025-10-06T00:58:37.053850Z","shell.execute_reply":"2025-10-06T00:58:38.379051Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, words):\n        super().__init__()\n        self.words = words\n        self.context_length = 4\n        self.chars = sorted(list(set(''.join(words))))\n        self.stoi = {s:i+1 for i, s in enumerate(self.chars)}\n        self.stoi['.'] = 0\n        self.itos = {i:s for s, i in self.stoi.items()}\n        self.vocabsize = len(self.itos)\n\n    def encode(self, in_char):\n        return self.stoi[in_char]\n\n    def decode(self, in_idx):\n        return self.itos[in_idx]\n\n    def build_dataset(self, words, block_size):\n        X, Y = [], []\n        for w in words:\n            context = [0] * block_size\n            for ch in w + '.':\n                ix = self.encode(ch)\n                X.append(context)\n                Y.append(ix)\n                context = context[1:] + [ix]\n        X = torch.tensor(X)\n        Y = torch.tensor(Y)\n        return X, Y\n\n    def splitdataset(self, test_percentage):\n        random.shuffle(self.words)\n        n = len(self.words) - int(test_percentage * len(self.words))\n        Xtr, Ytr = self.build_dataset(self.words[:n], self.context_length)\n        Xte, Yte = self.build_dataset(self.words[n:], self.context_length)\n        return Xtr, Ytr, Xte, Yte","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:00:03.982986Z","iopub.execute_input":"2025-10-06T01:00:03.983306Z","iopub.status.idle":"2025-10-06T01:00:03.993489Z","shell.execute_reply.started":"2025-10-06T01:00:03.983277Z","shell.execute_reply":"2025-10-06T01:00:03.992651Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"words = open('tamil_names.txt','r').read().splitlines();","metadata":{"execution":{"iopub.status.busy":"2025-10-06T01:00:06.613085Z","iopub.execute_input":"2025-10-06T01:00:06.613385Z","iopub.status.idle":"2025-10-06T01:00:06.620670Z","shell.execute_reply.started":"2025-10-06T01:00:06.613353Z","shell.execute_reply":"2025-10-06T01:00:06.619784Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"word_dataset = Dataset(words)\nXtr, Ytr, Xte, Yte = word_dataset.splitdataset(0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:43.478717Z","iopub.execute_input":"2025-10-06T01:13:43.479051Z","iopub.status.idle":"2025-10-06T01:13:43.670955Z","shell.execute_reply.started":"2025-10-06T01:13:43.479017Z","shell.execute_reply":"2025-10-06T01:13:43.670103Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"class BigramLinear(nn.Module):\n    def __init__(self, in_features, out_features, bias = True):\n        super().__init__()\n        self.weight = nn.Parameter(torch.randn((out_features, in_features)))\n        if bias:\n            self.bias = nn.Parameter(torch.randn(out_features))\n        else:\n            self.bias = None\n\n    def forward(self, x):\n        out  = x @ self.weight.T\n        if self.bias is not None:\n            out += self.bias\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:45.596814Z","iopub.execute_input":"2025-10-06T01:13:45.597113Z","iopub.status.idle":"2025-10-06T01:13:45.603213Z","shell.execute_reply.started":"2025-10-06T01:13:45.597080Z","shell.execute_reply":"2025-10-06T01:13:45.602233Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class BigramEmbedding(nn.Module):\n    def __init__(self, vocab_size, embed_dim):\n        super().__init__()\n        self.weight = nn.Parameter(torch.randn(vocab_size, embed_dim))\n\n    def forward(self, x):\n        return self.weight[x]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:48.428456Z","iopub.execute_input":"2025-10-06T01:13:48.428744Z","iopub.status.idle":"2025-10-06T01:13:48.434072Z","shell.execute_reply.started":"2025-10-06T01:13:48.428712Z","shell.execute_reply":"2025-10-06T01:13:48.433188Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"class Bigram(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, context_length):\n        super().__init__()\n        self.context_length = context_length\n        self.embedding = BigramEmbedding(vocab_size, embedding_dim)   \n        self.input_dim = embedding_dim * context_length\n        self.fc1 = BigramLinear(self.input_dim, hidden_dim)\n        self.fc2 = BigramLinear(hidden_dim, vocab_size)\n\n    def nograd(self):\n        pass\n\n    def fit(self, x, y, epochs, batch_size):\n        opt = torch.optim.SGD(self.parameters(), lr=0.1)\n        losses = []\n        for i in tqdm(range(epochs)):\n            x_batch, y_batch = self.generate_batch(x, y, batch_size)\n            logits, loss = self(x_batch, y_batch)\n            opt.zero_grad()\n            loss.backward()\n            losses.append(loss.log10().item())\n            opt.step()\n        return losses\n                \n    def forward(self, in_seq, out_seq):\n        embed = self.embedding(in_seq)\n        x = embed.view(embed.shape[0], -1)\n        l1 = self.fc1(x)\n        h = torch.tanh(l1)\n        logits = self.fc2(h)\n        loss = F.cross_entropy(logits, out_seq)\n        return logits, loss\n\n    def generate_batch(self, x, y, batch_size):\n        ix = torch.randint(0, x.shape[0], (batch_size,))\n        return x[ix], y[ix]\n\n    def generate(self, start_word):\n        context = [0] * self.context_length\n        context[-1] = start_word\n        out = []\n        while True:\n            x = self.embedding(torch.tensor([context]))\n            x = x.view(1, -1)\n            h = torch.tanh(self.fc1(x))\n            logits = self.fc2(h)\n            probs = F.softmax(logits, dim=1)\n            ix = torch.multinomial(probs, num_samples=1).item()\n            context = context[1:] + [ix]\n            out.append(ix)\n            if ix == 0:\n                break\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:50.619237Z","iopub.execute_input":"2025-10-06T01:13:50.619588Z","iopub.status.idle":"2025-10-06T01:13:50.631889Z","shell.execute_reply.started":"2025-10-06T01:13:50.619551Z","shell.execute_reply":"2025-10-06T01:13:50.631055Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"vocab_size = 50\nembedding_dim = 10\ninput_dim = 40\nhidden_dim = 200\nbatch_size = 32\ncontext_length = 4\nmodel = Bigram(vocab_size, embedding_dim, hidden_dim, context_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:56.162052Z","iopub.execute_input":"2025-10-06T01:13:56.162305Z","iopub.status.idle":"2025-10-06T01:13:56.167418Z","shell.execute_reply.started":"2025-10-06T01:13:56.162279Z","shell.execute_reply":"2025-10-06T01:13:56.166726Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"losses = model.fit(x = Xtr, y = Ytr, epochs = 200000, batch_size = 32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:13:59.147994Z","iopub.execute_input":"2025-10-06T01:13:59.148292Z","iopub.status.idle":"2025-10-06T01:16:06.732667Z","shell.execute_reply.started":"2025-10-06T01:13:59.148261Z","shell.execute_reply":"2025-10-06T01:16:06.731807Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 200000/200000 [02:07<00:00, 1567.73it/s]\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"print(''.join(word_dataset.decode(i) for i in model.generate(word_dataset.encode('.'))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T01:16:26.061892Z","iopub.execute_input":"2025-10-06T01:16:26.062211Z","iopub.status.idle":"2025-10-06T01:16:26.069812Z","shell.execute_reply.started":"2025-10-06T01:16:26.062160Z","shell.execute_reply":"2025-10-06T01:16:26.069049Z"}},"outputs":[{"name":"stdout","text":"இறைமகன்.\n","output_type":"stream"}],"execution_count":95}]}
