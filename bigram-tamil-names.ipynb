{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T00:58:37.053939Z",
     "iopub.status.busy": "2025-10-06T00:58:37.053566Z",
     "iopub.status.idle": "2025-10-06T00:58:38.379932Z",
     "shell.execute_reply": "2025-10-06T00:58:38.379051Z",
     "shell.execute_reply.started": "2025-10-06T00:58:37.053850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:00:03.983306Z",
     "iopub.status.busy": "2025-10-06T01:00:03.982986Z",
     "iopub.status.idle": "2025-10-06T01:00:03.993489Z",
     "shell.execute_reply": "2025-10-06T01:00:03.992651Z",
     "shell.execute_reply.started": "2025-10-06T01:00:03.983277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, words):\n",
    "        super().__init__()\n",
    "        self.words = words\n",
    "        self.context_length = 4\n",
    "        self.chars = sorted(list(set(''.join(words))))\n",
    "        self.stoi = {s:i+1 for i, s in enumerate(self.chars)}\n",
    "        self.stoi['.'] = 0\n",
    "        self.itos = {i:s for s, i in self.stoi.items()}\n",
    "        self.vocabsize = len(self.itos)\n",
    "\n",
    "    def encode(self, in_char):\n",
    "        return self.stoi[in_char]\n",
    "\n",
    "    def decode(self, in_idx):\n",
    "        return self.itos[in_idx]\n",
    "\n",
    "    def build_dataset(self, words, block_size):\n",
    "        X, Y = [], []\n",
    "        for w in words:\n",
    "            context = [0] * block_size\n",
    "            for ch in w + '.':\n",
    "                ix = self.encode(ch)\n",
    "                X.append(context)\n",
    "                Y.append(ix)\n",
    "                context = context[1:] + [ix]\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        return X, Y\n",
    "\n",
    "    def splitdataset(self, test_percentage):\n",
    "        random.shuffle(self.words)\n",
    "        n = len(self.words) - int(test_percentage * len(self.words))\n",
    "        Xtr, Ytr = self.build_dataset(self.words[:n], self.context_length)\n",
    "        Xte, Yte = self.build_dataset(self.words[n:], self.context_length)\n",
    "        return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:00:06.613385Z",
     "iopub.status.busy": "2025-10-06T01:00:06.613085Z",
     "iopub.status.idle": "2025-10-06T01:00:06.620670Z",
     "shell.execute_reply": "2025-10-06T01:00:06.619784Z",
     "shell.execute_reply.started": "2025-10-06T01:00:06.613353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "words = open('tamil_names.txt','r').read().splitlines();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:43.479051Z",
     "iopub.status.busy": "2025-10-06T01:13:43.478717Z",
     "iopub.status.idle": "2025-10-06T01:13:43.670955Z",
     "shell.execute_reply": "2025-10-06T01:13:43.670103Z",
     "shell.execute_reply.started": "2025-10-06T01:13:43.479017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_dataset = Dataset(words)\n",
    "Xtr, Ytr, Xte, Yte = word_dataset.splitdataset(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:45.597113Z",
     "iopub.status.busy": "2025-10-06T01:13:45.596814Z",
     "iopub.status.idle": "2025-10-06T01:13:45.603213Z",
     "shell.execute_reply": "2025-10-06T01:13:45.602233Z",
     "shell.execute_reply.started": "2025-10-06T01:13:45.597080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BigramLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn((out_features, in_features)))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(out_features))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out  = x @ self.weight.T\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:48.428744Z",
     "iopub.status.busy": "2025-10-06T01:13:48.428456Z",
     "iopub.status.idle": "2025-10-06T01:13:48.434072Z",
     "shell.execute_reply": "2025-10-06T01:13:48.433188Z",
     "shell.execute_reply.started": "2025-10-06T01:13:48.428712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BigramEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weight[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:50.619588Z",
     "iopub.status.busy": "2025-10-06T01:13:50.619237Z",
     "iopub.status.idle": "2025-10-06T01:13:50.631889Z",
     "shell.execute_reply": "2025-10-06T01:13:50.631055Z",
     "shell.execute_reply.started": "2025-10-06T01:13:50.619551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, context_length):\n",
    "        super().__init__()\n",
    "        self.context_length = context_length\n",
    "        self.embedding = BigramEmbedding(vocab_size, embedding_dim)   \n",
    "        self.input_dim = embedding_dim * context_length\n",
    "        self.fc1 = BigramLinear(self.input_dim, hidden_dim)\n",
    "        self.fc2 = BigramLinear(hidden_dim, vocab_size)\n",
    "\n",
    "    def nograd(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y, epochs, batch_size):\n",
    "        opt = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "        losses = []\n",
    "        for i in tqdm(range(epochs)):\n",
    "            x_batch, y_batch = self.generate_batch(x, y, batch_size)\n",
    "            logits = self(x_batch)\n",
    "            loss = F.cross_entropy(logits, y_batch)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            losses.append(loss.log10().item())\n",
    "            opt.step()\n",
    "        return losses\n",
    "                \n",
    "    def forward(self, in_seq):\n",
    "        embed = self.embedding(in_seq)\n",
    "        x = embed.view(embed.shape[0], -1)\n",
    "        l1 = self.fc1(x)\n",
    "        h = torch.tanh(l1)\n",
    "        logits = self.fc2(h)\n",
    "        return logits\n",
    "\n",
    "    def generate_batch(self, x, y, batch_size):\n",
    "        ix = torch.randint(0, x.shape[0], (batch_size,))\n",
    "        return x[ix], y[ix]\n",
    "\n",
    "    def generate(self, start_word):\n",
    "        context = [0] * self.context_length\n",
    "        context[-1] = start_word\n",
    "        out = []\n",
    "        while True:\n",
    "            x = self.embedding(torch.tensor([context]))\n",
    "            x = x.view(1, -1)\n",
    "            h = torch.tanh(self.fc1(x))\n",
    "            logits = self.fc2(h)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1).item()\n",
    "            context = context[1:] + [ix]\n",
    "            out.append(ix)\n",
    "            if ix == 0:\n",
    "                break\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:56.162305Z",
     "iopub.status.busy": "2025-10-06T01:13:56.162052Z",
     "iopub.status.idle": "2025-10-06T01:13:56.167418Z",
     "shell.execute_reply": "2025-10-06T01:13:56.166726Z",
     "shell.execute_reply.started": "2025-10-06T01:13:56.162279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 50\n",
    "embedding_dim = 10\n",
    "input_dim = 40\n",
    "hidden_dim = 200\n",
    "batch_size = 32\n",
    "context_length = 4\n",
    "model = Bigram(vocab_size, embedding_dim, hidden_dim, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:13:59.148292Z",
     "iopub.status.busy": "2025-10-06T01:13:59.147994Z",
     "iopub.status.idle": "2025-10-06T01:16:06.732667Z",
     "shell.execute_reply": "2025-10-06T01:16:06.731807Z",
     "shell.execute_reply.started": "2025-10-06T01:13:59.148261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:03<00:00, 3129.59it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = model.fit(x = Xtr, y = Ytr, epochs = 200000, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T01:16:26.062211Z",
     "iopub.status.busy": "2025-10-06T01:16:26.061892Z",
     "iopub.status.idle": "2025-10-06T01:16:26.069812Z",
     "shell.execute_reply": "2025-10-06T01:16:26.069049Z",
     "shell.execute_reply.started": "2025-10-06T01:16:26.062160Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ஆதியரசன்யார்.\n"
     ]
    }
   ],
   "source": [
    "print(''.join(word_dataset.decode(i) for i in model.generate(word_dataset.encode('.'))))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8405762,
     "sourceId": 13264607,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30154,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
